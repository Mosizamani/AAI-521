<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>1a9e45cb5e5840beb9094007af95160e</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div class="cell markdown" id="3BckDA-T0zzd">
<p><strong>Part 1- Neural Network</strong></p>
</div>
<div class="cell code" data-execution_count="2" id="PEwC6Ptd0tFK">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> PIL</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> PIL.Image</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow_datasets <span class="im">as</span> tfds</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pathlib</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> keras.datasets.fashion_mnist <span class="im">as</span> fashion_mnist</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="3"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="BKkBCAvyA_Ba" data-outputId="8c5ffb89-6123-421b-e64c-7e3fe8a554dd">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>(X_train, y_train), (X_test, y_test) <span class="op">=</span> fashion_mnist.load_data()</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>class_names <span class="op">=</span> [<span class="st">&#39;T-shirt/top&#39;</span>, <span class="st">&#39;Trouser&#39;</span>, <span class="st">&#39;Pullover&#39;</span>, <span class="st">&#39;Dress&#39;</span>, <span class="st">&#39;Coat&#39;</span>,</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>               <span class="st">&#39;Sandal&#39;</span>, <span class="st">&#39;Shirt&#39;</span>, <span class="st">&#39;Sneaker&#39;</span>, <span class="st">&#39;Bag&#39;</span>, <span class="st">&#39;Ankle boot&#39;</span>]</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># plot 4 images as gray scale</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">25</span>):</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">5</span>,<span class="dv">5</span>,i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    plt.xticks([])</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    plt.yticks([])</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    plt.grid(<span class="va">False</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    plt.imshow(X_train[i], cmap<span class="op">=</span>plt.cm.binary)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(class_names[y_train[i]])</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X_train.shape)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X_test.shape)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(class_names)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz
29515/29515 ━━━━━━━━━━━━━━━━━━━━ 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz
26421880/26421880 ━━━━━━━━━━━━━━━━━━━━ 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz
5148/5148 ━━━━━━━━━━━━━━━━━━━━ 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz
4422102/4422102 ━━━━━━━━━━━━━━━━━━━━ 0s 0us/step
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_61b6b11f6d9241a19833cd3b263dc8fe/abfec39169b1d8f9d4420841f5e5ae1d9e566c95.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>(60000, 28, 28)
(10000, 28, 28)
[&#39;T-shirt/top&#39;, &#39;Trouser&#39;, &#39;Pullover&#39;, &#39;Dress&#39;, &#39;Coat&#39;, &#39;Sandal&#39;, &#39;Shirt&#39;, &#39;Sneaker&#39;, &#39;Bag&#39;, &#39;Ankle boot&#39;]
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="4" id="b1h8Cm49BUyT">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># flatten 28*28 images to a 784 vector for each image</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>IMG_HEIGHT<span class="op">=</span><span class="dv">28</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>IMG_WIDTH<span class="op">=</span> <span class="dv">28</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>channels <span class="op">=</span><span class="dv">1</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="5" id="utUGzk-KBWkL">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># normalize inputs from 0-255 to 0-1</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X_train <span class="op">/</span> <span class="dv">255</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> X_test <span class="op">/</span> <span class="dv">255</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="6"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="MPK6FS_1BWry" data-outputId="81c2776f-b00b-424e-f075-5d86efecc66e">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Create the model here</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> tf.keras.losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> tf.keras.Sequential([</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>                             tf.keras.layers.Flatten(input_shape<span class="op">=</span>(IMG_HEIGHT, IMG_WIDTH)),</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>                             tf.keras.layers.Dense(<span class="dv">128</span>, activation<span class="op">=</span> <span class="st">&#39;relu&#39;</span>),</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>                             tf.keras.layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span> <span class="st">&#39;softmax&#39;</span>)])</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">&#39;adam&#39;</span>, loss<span class="op">=</span> loss_fn, metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="9"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="B8naX9BlBWxJ" data-outputId="5696ed5e-e737-4360-92d5-276d337b0316">
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model here</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>hist <span class="op">=</span> model.fit(X_train, y_train, validation_split<span class="op">=</span><span class="fl">0.2</span>, epochs<span class="op">=</span><span class="dv">20</span>, batch_size<span class="op">=</span><span class="dv">128</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 1/20
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.9048 - loss: 0.2625 - val_accuracy: 0.8832 - val_loss: 0.3211
Epoch 2/20
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.9055 - loss: 0.2556 - val_accuracy: 0.8861 - val_loss: 0.3182
Epoch 3/20
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.9115 - loss: 0.2451 - val_accuracy: 0.8827 - val_loss: 0.3253
Epoch 4/20
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.9154 - loss: 0.2344 - val_accuracy: 0.8861 - val_loss: 0.3199
Epoch 5/20
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.9151 - loss: 0.2332 - val_accuracy: 0.8878 - val_loss: 0.3141
Epoch 6/20
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.9165 - loss: 0.2273 - val_accuracy: 0.8824 - val_loss: 0.3318
Epoch 7/20
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.9223 - loss: 0.2132 - val_accuracy: 0.8893 - val_loss: 0.3078
Epoch 8/20
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.9206 - loss: 0.2151 - val_accuracy: 0.8914 - val_loss: 0.3072
Epoch 9/20
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step - accuracy: 0.9216 - loss: 0.2113 - val_accuracy: 0.8886 - val_loss: 0.3131
Epoch 10/20
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step - accuracy: 0.9268 - loss: 0.2010 - val_accuracy: 0.8847 - val_loss: 0.3240
Epoch 11/20
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.9263 - loss: 0.2022 - val_accuracy: 0.8813 - val_loss: 0.3457
Epoch 12/20
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.9284 - loss: 0.1941 - val_accuracy: 0.8925 - val_loss: 0.3147
Epoch 13/20
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.9334 - loss: 0.1848 - val_accuracy: 0.8857 - val_loss: 0.3278
Epoch 14/20
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.9334 - loss: 0.1848 - val_accuracy: 0.8867 - val_loss: 0.3229
Epoch 15/20
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.9313 - loss: 0.1840 - val_accuracy: 0.8892 - val_loss: 0.3277
Epoch 16/20
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.9340 - loss: 0.1792 - val_accuracy: 0.8907 - val_loss: 0.3170
Epoch 17/20
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.9383 - loss: 0.1731 - val_accuracy: 0.8908 - val_loss: 0.3318
Epoch 18/20
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.9409 - loss: 0.1637 - val_accuracy: 0.8907 - val_loss: 0.3287
Epoch 19/20
375/375 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.9394 - loss: 0.1657 - val_accuracy: 0.8929 - val_loss: 0.3216
Epoch 20/20
375/375 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - accuracy: 0.9427 - loss: 0.1575 - val_accuracy: 0.8906 - val_loss: 0.3273
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="10"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:472}"
id="gKclnmVEFNFh" data-outputId="544a5328-ee6a-46df-8dd4-fdfdc5c709fa">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>plt.plot(hist.history[<span class="st">&#39;accuracy&#39;</span>])</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>plt.plot(hist.history[<span class="st">&#39;val_accuracy&#39;</span>])</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;model accuracy&#39;</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;accuracy&#39;</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;epoch&#39;</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>plt.legend([<span class="st">&#39;train&#39;</span>, <span class="st">&#39;test&#39;</span>], loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>plt.plot(hist.history[<span class="st">&#39;loss&#39;</span>])</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>plt.plot(hist.history[<span class="st">&#39;val_loss&#39;</span>])</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;model loss&#39;</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;loss&#39;</span>)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;epoch&#39;</span>)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>plt.legend([<span class="st">&#39;train&#39;</span>, <span class="st">&#39;test&#39;</span>], loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_61b6b11f6d9241a19833cd3b263dc8fe/26c49e16464dbdb7107b9a2831bd22322909da89.png" /></p>
</div>
</div>
<div class="cell code" id="hc97p1jyFU8Z">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Write your understanding about this model here</span></span></code></pre></div>
</div>
<section id="write-your-understanding-about-this-model-here"
class="cell markdown" id="zbDHmfXORga1">
<h2>Write your understanding about this model here</h2>
<p>First, the required libraries were imported. Then, the desired
dataset, which consists of images and their corresponding labels, was
loaded. The dataset was split into training and testing sets, and some
samples were displayed to provide a visual insight into the data.</p>
<p>Next, the image size was determined, and grayscale images with a
single channel were used. The data was normalized to improve
compatibility with neural network models and ensure faster, more stable
training.</p>
<p>After preprocessing, the model was defined using a Sequential
architecture. Key design choices included:</p>
<p>ReLU activation in hidden layers, which replaces negative values with
zero and helps prevent vanishing gradients.</p>
<p>Softmax activation in the output layer, which converts logits into
probabilities for multi-class classification.</p>
<p>The Adam optimizer, which efficiently updates model weights to
minimize the loss function, guiding the network to learn correctly.</p>
<p>Sparse categorical cross-entropy as the loss function, which measures
how far off the model’s predictions are from the true labels.</p>
<p>Accuracy as a metric, to track the model’s performance during both
training and validation.</p>
<p>After training the initial model, I experimented with different
numbers of epochs: [10, 20, 50, 100, 150, 200]. It was observed that, in
general, as the number of epochs increased, the model’s validation
accuracy initially improved. However, after a certain point, overfitting
occurred, indicated by increasing validation loss and decreasing
validation accuracy.</p>
<p>Here are the results for different epochs:</p>
<p>10 Epochs <img src="epoch10.png" alt="10 epochs" width="300"/></p>
<p>20 Epochs <img src="epoch20.png" alt="20 epochs" width="300"/></p>
<p>50 Epochs <img src="epoch50.png" alt="50 epochs" width="300"/></p>
<p>100 Epochs <img src="epoch100.png" alt="100 epochs" width="300"/></p>
<p>150 Epochs <img src="epoch150.png" alt="150 epochs" width="300"/></p>
<p>200 Epochs <img src="epoch200.png" alt="200 epochs" width="300"/></p>
<p>This analysis shows that the number of epochs is a critical
hyperparameter. Optimizing it is essential not only to maximize accuracy
and minimize loss but also to prevent overfitting, ensuring that the
model generalizes well to unseen data.</p>
</section>
<div class="cell markdown" id="cUzANN4GFbDQ">
<p><strong>Part 2- Image Processing</strong></p>
</div>
<div class="cell markdown" id="UeWG0qAl24_D">
<p>Load the Flower photo dataset from tensorflow repository</p>
</div>
<div class="cell code" data-execution_count="11"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="ja08yv0p23Fc" data-outputId="da490937-4bd5-43d9-9c0d-dccd6026024f">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>dataset_url <span class="op">=</span> <span class="st">&quot;https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz&quot;</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>data_dir <span class="op">=</span> tf.keras.utils.get_file(origin<span class="op">=</span>dataset_url,</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>                                   fname<span class="op">=</span><span class="st">&#39;flower_photos&#39;</span>,</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>                                   untar<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>data_dir <span class="op">=</span> pathlib.Path(data_dir)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>data_dir <span class="op">=</span> data_dir <span class="op">/</span> <span class="st">&quot;flower_photos&quot;</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz
228813984/228813984 ━━━━━━━━━━━━━━━━━━━━ 1s 0us/step
</code></pre>
</div>
</div>
<div class="cell markdown" id="6crhha9K3amC">
<p><em>a) How many images we can find in this dataset?</em></p>
</div>
<div class="cell code" data-execution_count="12"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="IRIQ3Q8F3aD-" data-outputId="1f18c464-f0f8-4a6f-bece-f50a9d3c7cc7">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>image_count <span class="op">=</span> <span class="bu">len</span>(<span class="bu">list</span>(data_dir.glob(<span class="st">&#39;*/*.jpg&#39;</span>)))  <span class="co">#This will count all the file with extension of jpg- You have to modify this part</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(image_count)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data_dir)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>3670
/root/.keras/datasets/flower_photos/flower_photos
</code></pre>
</div>
</div>
<div class="cell markdown" id="GBGJQJRs4UZ6">
<p><em>b) The list of subfolders are:</em></p>
<ul>
<li>daisy</li>
<li>dandelion</li>
<li>roses</li>
<li>sunflowers</li>
<li>tulips</li>
</ul>
<p>You can look into any of the subfolders to see images stored over
there. You can look into the folder using: data_dir.glob('tulips/*') For
this part use Pillow (PIL) to show at least one flower from each
subfolder</p>
</div>
<div class="cell code" data-execution_count="15"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:387}"
id="7RH3ssXo4NEU" data-outputId="6b8bcfe5-8d01-46a7-c0ce-45d5c380f78b">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># tulips = list()    #This line stores the list of data in subfolder</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co"># PIL.Image.open(str(tulips[5]))              # Use Pillow here to plot the image</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Path to the tulips folder</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>tulips_dir <span class="op">=</span> data_dir <span class="op">/</span> <span class="st">&quot;tulips&quot;</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Get a list of all .jpg images in the tulips folder</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>tulips <span class="op">=</span> <span class="bu">list</span>(tulips_dir.glob(<span class="st">&#39;*.jpg&#39;</span>))</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the numbers of tulip images</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>num_tulips <span class="op">=</span> <span class="bu">len</span>(tulips)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the numbers of tulip images</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Number of tulip images:&quot;</span>, num_tulips)</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Now you can open an image</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> Image.<span class="bu">open</span>(<span class="bu">str</span>(tulips[<span class="dv">75</span>]))  <span class="co"># This will work if there are at least 6 images</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Display it inline</span></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>plt.imshow(img)</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">&#39;off&#39;</span>)  <span class="co"># turn off axis</span></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Number of tulip images: 799
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_61b6b11f6d9241a19833cd3b263dc8fe/d0b33bd1442d627e7d0718ebc5b4e931e032f85c.png" /></p>
</div>
</div>
<div class="cell markdown" id="nbT0v_EbBcts">
<p><em>c) Use Keras to resize all the images into same dimension
180x180</em></p>
</div>
<div class="cell code" data-execution_count="16" id="2OeppYZZ6tGp">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>img_height <span class="op">=</span> <span class="dv">180</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>img_width <span class="op">=</span> <span class="dv">180</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="17"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="Xv6Qd59HB6Ty" data-outputId="07387514-d0f4-4658-86cc-b22ac957af91">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert all the images in data_dir folder into 180x180 using tf.kera.utils.image_dataset_from_directory</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Modify following code</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>train_ds <span class="op">=</span> tf.keras.utils.image_dataset_from_directory(</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    data_dir,               <span class="co"># path to the main dataset folder</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    labels<span class="op">=</span><span class="st">&#39;inferred&#39;</span>,      <span class="co"># automatically infer labels from folder names</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    label_mode<span class="op">=</span><span class="st">&#39;int&#39;</span>,       <span class="co"># use integer labels</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    image_size<span class="op">=</span>(<span class="dv">180</span>, <span class="dv">180</span>),  <span class="co"># resize all images to 180x180</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">32</span>,          <span class="co"># number of images per batch</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">True</span>,           <span class="co"># shuffle dataset</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    seed<span class="op">=</span><span class="dv">123</span>,               <span class="co"># for reproducibility</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span><span class="fl">0.2</span>,   <span class="co"># reserve 20% for validation</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    subset<span class="op">=</span><span class="st">&#39;training&#39;</span>       <span class="co"># this is the training subset</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Check class names</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Classes:&quot;</span>, train_ds.class_names)</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect a batch</span></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> images, labels <span class="kw">in</span> train_ds.take(<span class="dv">1</span>):</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Batch image shape:&quot;</span>, images.shape)</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Batch labels:&quot;</span>, labels)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Found 3670 files belonging to 5 classes.
Using 2936 files for training.
Classes: [&#39;daisy&#39;, &#39;dandelion&#39;, &#39;roses&#39;, &#39;sunflowers&#39;, &#39;tulips&#39;]
Batch image shape: (32, 180, 180, 3)
Batch labels: tf.Tensor([2 1 4 3 1 2 1 2 4 1 4 4 3 4 1 2 0 4 1 1 1 4 3 2 3 1 4 2 2 3 4 3], shape=(32,), dtype=int32)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="18"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="5lJhgCYbCOfE" data-outputId="23e47405-ea93-45fb-ccd7-a68340380898">
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the same strategy to create validation data, this time from validation subset</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>val_ds <span class="op">=</span> tf.keras.utils.image_dataset_from_directory(</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    data_dir,</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    labels<span class="op">=</span><span class="st">&#39;inferred&#39;</span>,</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    label_mode<span class="op">=</span><span class="st">&#39;int&#39;</span>,</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    image_size<span class="op">=</span>(<span class="dv">180</span>, <span class="dv">180</span>),</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    seed<span class="op">=</span><span class="dv">123</span>,</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span><span class="fl">0.2</span>,  <span class="co"># same split as above</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>    subset<span class="op">=</span><span class="st">&#39;validation&#39;</span>     <span class="co"># this is the validation subset</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Found 3670 files belonging to 5 classes.
Using 734 files for validation.
</code></pre>
</div>
</div>
<div class="cell markdown" id="PTPxipBpDWwS">
<p>d) <em>You can use</em> <code>train_ds.class_names</code> <em>command
to get the list of labels. Write a code to randomly show 9 images from
training data while printing their label on top of the image.</em></p>
</div>
<div class="cell code" data-execution_count="27"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:829}"
id="nVV37LxhCssU" data-outputId="7e36fd7b-babb-4f45-feb8-09a2715563ee">
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>class_names <span class="op">=</span> train_ds.class_names</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Take one batch from the dataset</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> images, labels <span class="kw">in</span> train_ds.take(<span class="dv">1</span>):</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Choose 9 random indices from the batch</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>    indices <span class="op">=</span> np.random.choice(images.shape[<span class="dv">0</span>], <span class="dv">9</span>, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, idx <span class="kw">in</span> <span class="bu">enumerate</span>(indices):</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>        ax <span class="op">=</span> plt.subplot(<span class="dv">3</span>, <span class="dv">3</span>, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>        plt.imshow(images[idx].numpy().astype(<span class="st">&quot;uint8&quot;</span>))  <span class="co"># Convert tensor to numpy for plt</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>        plt.title(class_names[labels[idx]])</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>        plt.axis(<span class="st">&quot;off&quot;</span>)</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_61b6b11f6d9241a19833cd3b263dc8fe/d85e821a44d683044f658a967d8220e317fe3b90.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="29"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:829}"
id="tsbW6euu7dmv" data-outputId="657f7b4c-336f-4075-d3f6-3a0e5e4bd7cd">
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Here, I used the validation images to show 9 of them randomly</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>class_names <span class="op">=</span> val_ds.class_names</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Take one batch from the dataset</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> images, labels <span class="kw">in</span> val_ds.take(<span class="dv">1</span>):</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Choose 9 random indices from the batch</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>    indices <span class="op">=</span> np.random.choice(images.shape[<span class="dv">0</span>], <span class="dv">9</span>, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, idx <span class="kw">in</span> <span class="bu">enumerate</span>(indices):</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>        ax <span class="op">=</span> plt.subplot(<span class="dv">3</span>, <span class="dv">3</span>, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>        plt.imshow(images[idx].numpy().astype(<span class="st">&quot;uint8&quot;</span>))  <span class="co"># Convert tensor to numpy for plt</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>        plt.title(class_names[labels[idx]])</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>        plt.axis(<span class="st">&quot;off&quot;</span>)</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_61b6b11f6d9241a19833cd3b263dc8fe/1afca94eb29ef151430d7b4c63aeb7a504d66de8.png" /></p>
</div>
</div>
<div class="cell code" id="SWpCGg3vDWC7">
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Please carefully review the images. What are some barriers that you can see in images for having a proper classification?</span></span></code></pre></div>
</div>
<div class="cell markdown" id="cY32mWtr8ouf">
<p>The first challenge I noticed in the dataset is the skill level of
the photographers. Some images are not focused on the intended object;
instead, the focus may be on other elements such as buildings, benches,
or people. In other cases, the camera distance varies significantly —
some shots are too far, while others are extremely close — which can
negatively impact training and validation, and consequently reduce
accuracy while increasing loss on test images.</p>
<p>Another factor is the lighting conditions when the photos were taken.
Sunlight affects how well the camera captures details, which can
influence the quality of the images. Additionally, some images suffer
from blurriness, either due to portrait mode on smartphones or autofocus
on professional cameras, making the target objects unclear.</p>
<p>The variety of objects within each image is also an issue. Images
containing multiple objects can make the training and validation process
more difficult, often resulting in lower model accuracy.</p>
<p>Finally, there are labeling errors. For example, one randomly
selected validation image was labeled as a tulip, but it actually
contained a human who is painting under an umbrella. If such mislabeled
images are included in the test set, the model may incorrectly predict
them as tulips, increasing false positives. In these cases, hybrid
supervision can be highly beneficial — an expert can review the dataset
and model outputs to improve overall accuracy and precision.</p>
</div>
<div class="cell markdown" id="JpDK4iDKw6LR">
<p><em>e</em> - <em>Now, we want to use preprocessing package in Keras
to apply different filters to the image. Apply the following procedures
to image data:</em></p>
<ul>
<li><em>Rescale the image by dividing by 255</em></li>
<li><em>Shear the image 20%</em></li>
<li><em>Zoom the image 20%</em></li>
<li><em>Horizontally flip the images</em></li>
</ul>
</div>
<div class="cell code" data-execution_count="30"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="MRHE6qngwwk3" data-outputId="ab43dc9c-678d-4b92-883b-c3573e2bcae5">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.preprocessing.image <span class="im">import</span> ImageDataGenerator</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>train_datagen <span class="op">=</span> ImageDataGenerator(</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    rescale<span class="op">=</span><span class="fl">1.</span><span class="op">/</span><span class="dv">255</span>,         <span class="co"># Rescale pixel values to [0,1]</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    shear_range<span class="op">=</span><span class="fl">0.2</span>,        <span class="co"># Apply shear transformation up to 20%</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    zoom_range<span class="op">=</span><span class="fl">0.2</span>,         <span class="co"># Apply random zoom up to 20%</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    horizontal_flip<span class="op">=</span><span class="va">True</span>,   <span class="co"># Randomly flip images horizontally</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span><span class="fl">0.2</span>    <span class="co"># Optional: reserve 20% for validation</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>)  <span class="co"># Modify this line of code</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>training_set <span class="op">=</span> train_datagen.flow_from_directory(</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;/root/.keras/datasets/flower_photos/flower_photos&#39;</span>,</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>    target_size<span class="op">=</span>(<span class="dv">180</span>, <span class="dv">180</span>), <span class="co"># Resize images to 180x180</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>    class_mode<span class="op">=</span><span class="st">&#39;categorical&#39;</span>, <span class="co"># For multi-class classification</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>    subset<span class="op">=</span><span class="st">&#39;training&#39;</span>,        <span class="co"># Subset for training</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">True</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>)   <span class="co"># Modify this line of code</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Optional: create validation set</span></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>validation_set <span class="op">=</span> train_datagen.flow_from_directory(</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;/root/.keras/datasets/flower_photos/flower_photos&#39;</span>,</span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>    target_size<span class="op">=</span>(<span class="dv">180</span>, <span class="dv">180</span>),</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>    class_mode<span class="op">=</span><span class="st">&#39;categorical&#39;</span>,</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>    subset<span class="op">=</span><span class="st">&#39;validation&#39;</span>,     <span class="co"># Subset for validation</span></span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">True</span></span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Found 2939 images belonging to 5 classes.
Found 731 images belonging to 5 classes.
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="32"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:829}"
id="tH1mxstKHorC" data-outputId="31083d80-4e6f-4a8e-a96d-979ff2dd5ec7">
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get one batch of images and labels from training set</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>images, labels <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(training_set))</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Get class names</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>class_names <span class="op">=</span> <span class="bu">list</span>(training_set.class_indices.keys())</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Display 9 images with their class names</span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">9</span>):</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> plt.subplot(<span class="dv">3</span>, <span class="dv">3</span>, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>    plt.imshow(images[i])  <span class="co"># Images are already rescaled to [0,1]</span></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>    plt.title(class_names[np.argmax(labels[i])])  <span class="co"># Convert one-hot label to class name</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">&quot;off&quot;</span>)</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_61b6b11f6d9241a19833cd3b263dc8fe/b721f5ad39c8b2eea2909efcf5cdff4605e42570.png" /></p>
</div>
</div>
<div class="cell markdown" id="bs7teD_nxOY_">
<p><strong>Part 3- OPENCV</strong>- Now use opencv for preprocessing.
Show first 9 images in dataset using Opencv. Before showing each image,
resize the images to 180x180.</p>
</div>
<div class="cell code" data-execution_count="60"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:807}"
id="8C9xj9PTKpSt" data-outputId="5b741599-ee9f-46b6-ffb4-2ddf079fb410">
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2                                   <span class="co"># OpenCV for image processing (read, transform, display)</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np                           <span class="co"># NumPy for array and matrix operations</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt              <span class="co"># Matplotlib for showing images</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random                                <span class="co"># Random for generating random transformations</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path                     <span class="co"># Path for handling file paths easily</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the dataset path</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>data_dir <span class="op">=</span> Path(<span class="st">&#39;/root/.keras/datasets/flower_photos/flower_photos&#39;</span>)  <span class="co"># Folder containing images</span></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Get a list of all .jpg images inside subfolders</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>list_of_images <span class="op">=</span> <span class="bu">list</span>(data_dir.glob(<span class="st">&#39;*/*.jpg&#39;</span>))   <span class="co"># Collect all image file paths</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))                      <span class="co"># Create a 12x12 inch figure for displaying images</span></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop over the first 9 images in the dataset</span></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">9</span>):                                <span class="co"># Repeat 9 times</span></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>    img_path <span class="op">=</span> <span class="bu">str</span>(list_of_images[i])             <span class="co"># Convert Path object to string (OpenCV needs string)</span></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> cv2.imread(img_path)                    <span class="co"># Read image using OpenCV (loads in BGR format)</span></span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2RGB)    <span class="co"># Convert color from BGR → RGB for Matplotlib</span></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> cv2.resize(img, (<span class="dv">180</span>, <span class="dv">180</span>))             <span class="co"># Resize the image to 180x180 pixels</span></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ---- Random Horizontal Flip ----</span></span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> random.random() <span class="op">&gt;</span> <span class="fl">0.5</span>:                     <span class="co"># 50% probability of flipping</span></span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> cv2.flip(img, <span class="dv">1</span>)                    <span class="co"># Flip image horizontally (mirror effect)</span></span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ---- Random Zoom ----</span></span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a>    zoom_factor <span class="op">=</span> <span class="dv">1</span> <span class="op">+</span> random.uniform(<span class="op">-</span><span class="fl">0.2</span>, <span class="fl">0.2</span>)   <span class="co"># Choose random zoom between 0.8× and 1.2×</span></span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>    h, w <span class="op">=</span> img.shape[:<span class="dv">2</span>]                          <span class="co"># Get image height and width</span></span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a>    new_h, new_w <span class="op">=</span> <span class="bu">int</span>(h <span class="op">*</span> zoom_factor), <span class="bu">int</span>(w <span class="op">*</span> zoom_factor)  <span class="co"># Compute new size</span></span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a>    zoomed <span class="op">=</span> cv2.resize(img, (new_w, new_h))      <span class="co"># Resize image according to zoom factor</span></span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> zoom_factor <span class="op">&gt;</span> <span class="dv">1</span>:                           <span class="co"># If zoomed in</span></span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a>        start_x <span class="op">=</span> (new_w <span class="op">-</span> w) <span class="op">//</span> <span class="dv">2</span>                <span class="co"># Compute x offset for cropping center</span></span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a>        start_y <span class="op">=</span> (new_h <span class="op">-</span> h) <span class="op">//</span> <span class="dv">2</span>                <span class="co"># Compute y offset for cropping center</span></span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> zoomed[start_y:start_y <span class="op">+</span> h, start_x:start_x <span class="op">+</span> w]  <span class="co"># Crop to original size</span></span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:                                         <span class="co"># If zoomed out</span></span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a>        pad_x <span class="op">=</span> (w <span class="op">-</span> new_w) <span class="op">//</span> <span class="dv">2</span>                  <span class="co"># Compute horizontal padding</span></span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a>        pad_y <span class="op">=</span> (h <span class="op">-</span> new_h) <span class="op">//</span> <span class="dv">2</span>                  <span class="co"># Compute vertical padding</span></span>
<span id="cb30-39"><a href="#cb30-39" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> cv2.copyMakeBorder(zoomed, pad_y, pad_y, pad_x, pad_x, cv2.BORDER_REFLECT)</span>
<span id="cb30-40"><a href="#cb30-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add reflected borders to fill back to 180×180</span></span>
<span id="cb30-41"><a href="#cb30-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-42"><a href="#cb30-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ---- Random Shear ----</span></span>
<span id="cb30-43"><a href="#cb30-43" aria-hidden="true" tabindex="-1"></a>    shear_factor <span class="op">=</span> random.uniform(<span class="op">-</span><span class="fl">0.2</span>, <span class="fl">0.2</span>)      <span class="co"># Random shear factor between -0.2 and +0.2</span></span>
<span id="cb30-44"><a href="#cb30-44" aria-hidden="true" tabindex="-1"></a>    M <span class="op">=</span> np.array([[<span class="dv">1</span>, shear_factor, <span class="dv">0</span>],           <span class="co"># Build affine transformation matrix</span></span>
<span id="cb30-45"><a href="#cb30-45" aria-hidden="true" tabindex="-1"></a>                  [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>]], dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb30-46"><a href="#cb30-46" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> cv2.warpAffine(img, M, (w, h), borderMode<span class="op">=</span>cv2.BORDER_REFLECT)</span>
<span id="cb30-47"><a href="#cb30-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply shear transformation while reflecting borders</span></span>
<span id="cb30-48"><a href="#cb30-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-49"><a href="#cb30-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ---- Rescale ----</span></span>
<span id="cb30-50"><a href="#cb30-50" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> img <span class="op">/</span> <span class="fl">255.0</span>                             <span class="co"># Normalize pixel values to range [0,1]</span></span>
<span id="cb30-51"><a href="#cb30-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-52"><a href="#cb30-52" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ---- Display ----</span></span>
<span id="cb30-53"><a href="#cb30-53" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">3</span>, <span class="dv">3</span>, i <span class="op">+</span> <span class="dv">1</span>)                      <span class="co"># Place each image in a 3×3 grid position</span></span>
<span id="cb30-54"><a href="#cb30-54" aria-hidden="true" tabindex="-1"></a>    plt.imshow(img)                               <span class="co"># Show the processed image</span></span>
<span id="cb30-55"><a href="#cb30-55" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">&#39;off&#39;</span>)                               <span class="co"># Hide axis ticks</span></span>
<span id="cb30-56"><a href="#cb30-56" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f&quot;Image </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">&quot;</span>)                     <span class="co"># Add image number as title</span></span>
<span id="cb30-57"><a href="#cb30-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-58"><a href="#cb30-58" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()                                <span class="co"># Adjust layout to prevent overlap</span></span>
<span id="cb30-59"><a href="#cb30-59" aria-hidden="true" tabindex="-1"></a>plt.show()                                        <span class="co"># Display all 9 processed images</span></span>
<span id="cb30-60"><a href="#cb30-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-61"><a href="#cb30-61" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_61b6b11f6d9241a19833cd3b263dc8fe/5f4b3a75da529ed68ee684161dd7c23be225af1e.png" /></p>
</div>
</div>
<div class="cell markdown" id="iasBW0CkvxMp">
<p>OpenCV uses BGR as its default colour order for images, matplotlib
uses RGB. When you display an image loaded with OpenCv in matplotlib the
channels will be back to front. The easiest way of fixing this is to use
OpenCV to explicitly convert it back to RGB, much like you do when
creating the greyscale image.
<code>RGB_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</code></p>
</div>
<div class="cell code" data-execution_count="80"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:774}"
id="FtHo9jIBL27m" data-outputId="20d95caa-1359-4c51-8983-94a7beab01f1">
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab.patches <span class="im">import</span> cv2_imshow  <span class="co"># This works in Google Colab</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> apply_blue_sunflower_filter(image_path):</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1 Load the image</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> cv2.imread(<span class="bu">str</span>(image_path))</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> img <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Error: Could not load image at </span><span class="sc">{</span>image_path<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2 Split image into color channels (BGR in OpenCV)</span></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>    b, g, r <span class="op">=</span> cv2.split(img)</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3 Apply the blue filter transformation</span></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>    new_b <span class="op">=</span> np.clip(r <span class="op">*</span> <span class="fl">1.2</span>, <span class="dv">0</span>, <span class="dv">255</span>).astype(np.uint8)  <span class="co"># boost blue tones</span></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>    new_g <span class="op">=</span> np.clip(g <span class="op">*</span> <span class="fl">1.0</span>, <span class="dv">0</span>, <span class="dv">255</span>).astype(np.uint8)  <span class="co"># keep green</span></span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>    new_r <span class="op">=</span> np.clip(b <span class="op">*</span> <span class="fl">0.5</span>, <span class="dv">0</span>, <span class="dv">255</span>).astype(np.uint8)  <span class="co"># cool down reds</span></span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4 Merge modified channels</span></span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>    blue_img <span class="op">=</span> cv2.merge([new_b, new_g, new_r])</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 5 Display results</span></span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Original Image:&quot;</span>)</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>    cv2_imshow(img)</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Blue Filtered Image:&quot;</span>)</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>    cv2_imshow(blue_img)</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span></span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Get all sunflower images as a list</span></span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a>sunflower_images <span class="op">=</span> <span class="bu">list</span>(data_dir.glob(<span class="st">&#39;sunflowers/*.jpg&#39;</span>))</span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Choose the image by index number (e.g., 34th image)</span></span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a>index <span class="op">=</span> <span class="dv">34</span></span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure index is valid</span></span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> index <span class="op">&lt;</span> <span class="bu">len</span>(sunflower_images):</span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a>    sunflower_path <span class="op">=</span> sunflower_images[index]</span>
<span id="cb31-44"><a href="#cb31-44" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Selected image: </span><span class="sc">{</span>sunflower_path<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb31-45"><a href="#cb31-45" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb31-46"><a href="#cb31-46" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot; Index </span><span class="sc">{</span>index<span class="sc">}</span><span class="ss"> is out of range! Only </span><span class="sc">{</span><span class="bu">len</span>(sunflower_images)<span class="sc">}</span><span class="ss"> images available.&quot;</span>)</span>
<span id="cb31-47"><a href="#cb31-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-48"><a href="#cb31-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the filter</span></span>
<span id="cb31-49"><a href="#cb31-49" aria-hidden="true" tabindex="-1"></a>apply_blue_sunflower_filter(sunflower_path)</span>
<span id="cb31-50"><a href="#cb31-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-51"><a href="#cb31-51" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Selected image: /root/.keras/datasets/flower_photos/flower_photos/sunflowers/4933822272_79af205b94.jpg
Original Image:
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_61b6b11f6d9241a19833cd3b263dc8fe/e594c194d0b65c2a41e587fcf501b64efe4ea37c.jpg" /></p>
</div>
<div class="output stream stdout">
<pre><code>Blue Filtered Image:
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_61b6b11f6d9241a19833cd3b263dc8fe/4b8f1e5f77ab7d242771e31756d468b8937d5c16.jpg" /></p>
</div>
<div class="output execute_result" data-execution_count="80">
<pre><code>1</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="82"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:588}"
id="mWHb30ex82tT" data-outputId="94a587cd-074d-4f0b-b214-cb9d2d69820f">
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab.patches <span class="im">import</span> cv2_imshow  <span class="co"># Works in Colab for displaying images</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> apply_blue_tulip_filter(image_path):</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1 Load the image</span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> cv2.imread(<span class="bu">str</span>(image_path))</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> img <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Error: Could not load image at </span><span class="sc">{</span>image_path<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2 Split image into BGR channels</span></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>    b, g, r <span class="op">=</span> cv2.split(img)</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3 Apply blue filter transformation</span></span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>    new_b <span class="op">=</span> np.clip(r <span class="op">*</span> <span class="fl">1.2</span>, <span class="dv">0</span>, <span class="dv">255</span>).astype(np.uint8)  <span class="co"># boost blue tones using original red</span></span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>    new_g <span class="op">=</span> np.clip(g <span class="op">*</span> <span class="fl">1.0</span>, <span class="dv">0</span>, <span class="dv">255</span>).astype(np.uint8)  <span class="co"># keep green similar</span></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>    new_r <span class="op">=</span> np.clip(b <span class="op">*</span> <span class="fl">0.5</span>, <span class="dv">0</span>, <span class="dv">255</span>).astype(np.uint8)  <span class="co"># reduce original blue intensity</span></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4 Merge the modified channels</span></span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>    blue_img <span class="op">=</span> cv2.merge([new_b, new_g, new_r])</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 5 Display images</span></span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Original Tulip Image:&quot;</span>)</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>    cv2_imshow(img)</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Blue Filtered Tulip Image:&quot;</span>)</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a>    cv2_imshow(blue_img)</span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span></span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Example usage for tulips ---</span></span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Path to the tulips folder</span></span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a>data_dir <span class="op">=</span> Path(<span class="st">&#39;/root/.keras/datasets/flower_photos/flower_photos&#39;</span>)</span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Get all tulip images as a list</span></span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a>tulip_images <span class="op">=</span> <span class="bu">list</span>(data_dir.glob(<span class="st">&#39;tulips/*.jpg&#39;</span>))</span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-43"><a href="#cb35-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Choose the image by index number (e.g., 34th image)</span></span>
<span id="cb35-44"><a href="#cb35-44" aria-hidden="true" tabindex="-1"></a>index <span class="op">=</span> <span class="dv">77</span></span>
<span id="cb35-45"><a href="#cb35-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-46"><a href="#cb35-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure index is valid</span></span>
<span id="cb35-47"><a href="#cb35-47" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> index <span class="op">&lt;</span> <span class="bu">len</span>(tulip_images):</span>
<span id="cb35-48"><a href="#cb35-48" aria-hidden="true" tabindex="-1"></a>    tulip_path <span class="op">=</span> tulip_images[index]</span>
<span id="cb35-49"><a href="#cb35-49" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Selected tulip image: </span><span class="sc">{</span>tulip_path<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb35-50"><a href="#cb35-50" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb35-51"><a href="#cb35-51" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Index </span><span class="sc">{</span>index<span class="sc">}</span><span class="ss"> is out of range! Only </span><span class="sc">{</span><span class="bu">len</span>(tulip_images)<span class="sc">}</span><span class="ss"> tulip images available.&quot;</span>)</span>
<span id="cb35-52"><a href="#cb35-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-53"><a href="#cb35-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the blue filter</span></span>
<span id="cb35-54"><a href="#cb35-54" aria-hidden="true" tabindex="-1"></a>apply_blue_tulip_filter(tulip_path)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Selected tulip image: /root/.keras/datasets/flower_photos/flower_photos/tulips/4550091966_7f3e0f8802_n.jpg
Original Tulip Image:
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_61b6b11f6d9241a19833cd3b263dc8fe/a19ecbb5f7ee5d4333f24c5c230a4eabbd51a1e5.jpg" /></p>
</div>
<div class="output stream stdout">
<pre><code>Blue Filtered Tulip Image:
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_61b6b11f6d9241a19833cd3b263dc8fe/ad7a95815e9f0f43c3b09a863769a39cb24ac6ca.jpg" /></p>
</div>
<div class="output execute_result" data-execution_count="82">
<pre><code>1</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="84"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:679}"
id="XXrf9lWk-02i" data-outputId="9d29bd66-35df-4630-9e0d-ebe61270870a">
<div class="sourceCode" id="cb39"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab.patches <span class="im">import</span> cv2_imshow  <span class="co"># Only for Colab</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> apply_curves(image_path, curve_points<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Apply a curves adjustment to an image, similar to Photoshop.</span></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a><span class="co">        image_path (str or Path): Path to the input image</span></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a><span class="co">        curve_points (list of tuples): List of (input, output) points to define the curve</span></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a><span class="co">                                       Values should be in [0, 255]</span></span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a><span class="co">        img_curved (numpy.ndarray): Image after curve adjustment</span></span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1️⃣ Load the image</span></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> cv2.imread(<span class="bu">str</span>(image_path))</span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> img <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Error: Could not load image at </span><span class="sc">{</span>image_path<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># OpenCV uses BGR format</span></span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a>    img_curved <span class="op">=</span> np.zeros_like(img)</span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2️⃣ Default curve if none provided (simple S-curve)</span></span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> curve_points <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a>        curve_points <span class="op">=</span> [(<span class="dv">0</span>, <span class="dv">0</span>), (<span class="dv">64</span>, <span class="dv">50</span>), (<span class="dv">128</span>, <span class="dv">128</span>), (<span class="dv">192</span>, <span class="dv">205</span>), (<span class="dv">255</span>, <span class="dv">255</span>)]</span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3️⃣ Generate the lookup table using linear interpolation</span></span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> [p[<span class="dv">0</span>] <span class="cf">for</span> p <span class="kw">in</span> curve_points]</span>
<span id="cb39-33"><a href="#cb39-33" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> [p[<span class="dv">1</span>] <span class="cf">for</span> p <span class="kw">in</span> curve_points]</span>
<span id="cb39-34"><a href="#cb39-34" aria-hidden="true" tabindex="-1"></a>    lut <span class="op">=</span> np.interp(np.arange(<span class="dv">256</span>), x, y).astype(np.uint8)</span>
<span id="cb39-35"><a href="#cb39-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-36"><a href="#cb39-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4️⃣ Apply the LUT to each channel</span></span>
<span id="cb39-37"><a href="#cb39-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):  <span class="co"># B, G, R channels</span></span>
<span id="cb39-38"><a href="#cb39-38" aria-hidden="true" tabindex="-1"></a>        img_curved[:, :, i] <span class="op">=</span> cv2.LUT(img[:, :, i], lut)</span>
<span id="cb39-39"><a href="#cb39-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-40"><a href="#cb39-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 5️⃣ Show the original and adjusted images</span></span>
<span id="cb39-41"><a href="#cb39-41" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Original Image:&quot;</span>)</span>
<span id="cb39-42"><a href="#cb39-42" aria-hidden="true" tabindex="-1"></a>    cv2_imshow(img)</span>
<span id="cb39-43"><a href="#cb39-43" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Curves Adjusted Image:&quot;</span>)</span>
<span id="cb39-44"><a href="#cb39-44" aria-hidden="true" tabindex="-1"></a>    cv2_imshow(img_curved)</span>
<span id="cb39-45"><a href="#cb39-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-46"><a href="#cb39-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span></span>
<span id="cb39-47"><a href="#cb39-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-48"><a href="#cb39-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-49"><a href="#cb39-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage:</span></span>
<span id="cb39-50"><a href="#cb39-50" aria-hidden="true" tabindex="-1"></a>data_dir <span class="op">=</span> Path(<span class="st">&#39;/root/.keras/datasets/flower_photos/flower_photos&#39;</span>)</span>
<span id="cb39-51"><a href="#cb39-51" aria-hidden="true" tabindex="-1"></a>tulip_path <span class="op">=</span> <span class="bu">list</span>(data_dir.glob(<span class="st">&#39;tulips/*.jpg&#39;</span>))[<span class="dv">10</span>]  <span class="co"># Pick 11th tulip image</span></span>
<span id="cb39-52"><a href="#cb39-52" aria-hidden="true" tabindex="-1"></a>apply_curves(tulip_path)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Original Image:
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_61b6b11f6d9241a19833cd3b263dc8fe/c35fc171924e73f8e61589106a6cd6f28db980c8.jpg" /></p>
</div>
<div class="output stream stdout">
<pre><code>Curves Adjusted Image:
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_61b6b11f6d9241a19833cd3b263dc8fe/032b00de3a91bdc1131190d7041acd8654f0337b.jpg" /></p>
</div>
<div class="output execute_result" data-execution_count="84">
<pre><code>1</code></pre>
</div>
</div>
<section id="an-idea-on-preprocessing-computer-vision-tasks"
class="cell markdown" id="d0LpuOWvHgHP">
<h2>An Idea on preprocessing Computer Vision Tasks</h2>
</section>
<div class="cell markdown" id="sp0QEl9bEJQR">
<p>I have developed an idea for applying filters to image datasets
inspired by Adobe Photoshop. With over 20 years of experience using
Photoshop, I have observed its powerful capability to apply filters
layer by layer. Each layer can be toggled on or off, allowing the user
to selectively apply effects, and the final desired result can be
flattened onto the original image.</p>
<p>The core concept is to create a Python class (can be several class
using different libraries such as PIL, OpenCV, Pytorch, etc.)that
encapsulates several useful image preprocessing filters as functions,
specifically designed for computer vision tasks. These filters can then
be sequentially applied to an image dataset. Each filter individually
modifies the dataset and may impact the performance of a machine
learning model trained on it.</p>
<p>Building on this, several parameter ranges can be defined for each
filter—for example, varying the brightness, contrast, blur intensity, or
color shifts. By systematically applying each filter (or combination of
filters) across these ranges and training the model, we can evaluate the
resulting accuracy and loss. Repeating this process over multiple
iterations allows us to identify the most effective sequence and
parameter settings for the filters.</p>
<p>Ultimately, this approach can automatically optimize the
preprocessing pipeline, producing a “filterized” model that maximizes
performance while minimizing loss. This method is especially applicable
to data-driven systems such as autonomous vehicles, drones, and
robotics, where optimal preprocessing of visual data is critical.
Additional enhancements, such as implementing Photoshop-like curves,
adjusting sharpness, and fine-tuning brightness and contrast, can
further improve the model’s robustness and accuracy.</p>
<p>Here is a sample minimalist code with above concept.</p>
</div>
<div class="cell code" data-execution_count="87"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="83vQv6EBNDe3" data-outputId="b30fe4cf-b4ac-45ca-bf19-4114db6b117d">
<div class="sourceCode" id="cb43"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.preprocessing.image <span class="im">import</span> ImageDataGenerator</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> layers, models</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Define a Filter Class</span></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ImageFilters:</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;A class that applies sequential filters to an image.&quot;&quot;&quot;</span></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, brightness<span class="op">=</span><span class="fl">1.0</span>, blur<span class="op">=</span><span class="dv">0</span>, flip<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.brightness <span class="op">=</span> brightness  <span class="co"># brightness factor</span></span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.blur <span class="op">=</span> blur              <span class="co"># Gaussian blur kernel size</span></span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.flip <span class="op">=</span> flip              <span class="co"># horizontal flip</span></span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="bu">apply</span>(<span class="va">self</span>, img):</span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 1. Adjust brightness</span></span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> cv2.convertScaleAbs(img, alpha<span class="op">=</span><span class="va">self</span>.brightness, beta<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 2. Apply blur if specified</span></span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.blur <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a>            img <span class="op">=</span> cv2.GaussianBlur(img, (<span class="va">self</span>.blur, <span class="va">self</span>.blur), <span class="dv">0</span>)</span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 3. Flip image horizontally</span></span>
<span id="cb43-29"><a href="#cb43-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.flip:</span>
<span id="cb43-30"><a href="#cb43-30" aria-hidden="true" tabindex="-1"></a>            img <span class="op">=</span> cv2.flip(img, <span class="dv">1</span>)</span>
<span id="cb43-31"><a href="#cb43-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-32"><a href="#cb43-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> img</span>
<span id="cb43-33"><a href="#cb43-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-34"><a href="#cb43-34" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb43-35"><a href="#cb43-35" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Load Dataset (Flowers)</span></span>
<span id="cb43-36"><a href="#cb43-36" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb43-37"><a href="#cb43-37" aria-hidden="true" tabindex="-1"></a>data_dir <span class="op">=</span> Path(<span class="st">&#39;/root/.keras/datasets/flower_photos/flower_photos&#39;</span>)</span>
<span id="cb43-38"><a href="#cb43-38" aria-hidden="true" tabindex="-1"></a>class_names <span class="op">=</span> [p.name <span class="cf">for</span> p <span class="kw">in</span> data_dir.iterdir() <span class="cf">if</span> p.is_dir()]</span>
<span id="cb43-39"><a href="#cb43-39" aria-hidden="true" tabindex="-1"></a>IMG_SIZE <span class="op">=</span> (<span class="dv">180</span>, <span class="dv">180</span>)</span>
<span id="cb43-40"><a href="#cb43-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-41"><a href="#cb43-41" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_images(folder, limit_per_class<span class="op">=</span><span class="dv">50</span>):</span>
<span id="cb43-42"><a href="#cb43-42" aria-hidden="true" tabindex="-1"></a>    images, labels <span class="op">=</span> [], []</span>
<span id="cb43-43"><a href="#cb43-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx, cls <span class="kw">in</span> <span class="bu">enumerate</span>(class_names):</span>
<span id="cb43-44"><a href="#cb43-44" aria-hidden="true" tabindex="-1"></a>        cls_dir <span class="op">=</span> data_dir<span class="op">/</span>cls</span>
<span id="cb43-45"><a href="#cb43-45" aria-hidden="true" tabindex="-1"></a>        img_paths <span class="op">=</span> <span class="bu">list</span>(cls_dir.glob(<span class="st">&#39;*.jpg&#39;</span>))[:limit_per_class]</span>
<span id="cb43-46"><a href="#cb43-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> img_path <span class="kw">in</span> img_paths:</span>
<span id="cb43-47"><a href="#cb43-47" aria-hidden="true" tabindex="-1"></a>            img <span class="op">=</span> cv2.imread(<span class="bu">str</span>(img_path))</span>
<span id="cb43-48"><a href="#cb43-48" aria-hidden="true" tabindex="-1"></a>            img <span class="op">=</span> cv2.resize(img, IMG_SIZE)</span>
<span id="cb43-49"><a href="#cb43-49" aria-hidden="true" tabindex="-1"></a>            images.append(img)</span>
<span id="cb43-50"><a href="#cb43-50" aria-hidden="true" tabindex="-1"></a>            labels.append(idx)</span>
<span id="cb43-51"><a href="#cb43-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(images), np.array(labels)</span>
<span id="cb43-52"><a href="#cb43-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-53"><a href="#cb43-53" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> load_images(data_dir)</span>
<span id="cb43-54"><a href="#cb43-54" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> tf.keras.utils.to_categorical(y, num_classes<span class="op">=</span><span class="bu">len</span>(class_names))</span>
<span id="cb43-55"><a href="#cb43-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-56"><a href="#cb43-56" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb43-57"><a href="#cb43-57" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Apply Random Filter Layer</span></span>
<span id="cb43-58"><a href="#cb43-58" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb43-59"><a href="#cb43-59" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> apply_random_filter_layer(X):</span>
<span id="cb43-60"><a href="#cb43-60" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Apply random filter parameters to each image.&quot;&quot;&quot;</span></span>
<span id="cb43-61"><a href="#cb43-61" aria-hidden="true" tabindex="-1"></a>    new_X <span class="op">=</span> []</span>
<span id="cb43-62"><a href="#cb43-62" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> img <span class="kw">in</span> X:</span>
<span id="cb43-63"><a href="#cb43-63" aria-hidden="true" tabindex="-1"></a>        f <span class="op">=</span> ImageFilters(</span>
<span id="cb43-64"><a href="#cb43-64" aria-hidden="true" tabindex="-1"></a>            brightness<span class="op">=</span>random.uniform(<span class="fl">0.8</span>, <span class="fl">1.2</span>),  <span class="co"># brightness range</span></span>
<span id="cb43-65"><a href="#cb43-65" aria-hidden="true" tabindex="-1"></a>            blur<span class="op">=</span>random.choice([<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">5</span>]),         <span class="co"># blur kernel choices</span></span>
<span id="cb43-66"><a href="#cb43-66" aria-hidden="true" tabindex="-1"></a>            flip<span class="op">=</span>random.choice([<span class="va">True</span>, <span class="va">False</span>])      <span class="co"># randomly flip</span></span>
<span id="cb43-67"><a href="#cb43-67" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb43-68"><a href="#cb43-68" aria-hidden="true" tabindex="-1"></a>        new_X.append(f.<span class="bu">apply</span>(img))</span>
<span id="cb43-69"><a href="#cb43-69" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(new_X)</span>
<span id="cb43-70"><a href="#cb43-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-71"><a href="#cb43-71" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply filter</span></span>
<span id="cb43-72"><a href="#cb43-72" aria-hidden="true" tabindex="-1"></a>X_filtered <span class="op">=</span> apply_random_filter_layer(X)</span>
<span id="cb43-73"><a href="#cb43-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-74"><a href="#cb43-74" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalize images</span></span>
<span id="cb43-75"><a href="#cb43-75" aria-hidden="true" tabindex="-1"></a>X_filtered <span class="op">=</span> X_filtered <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb43-76"><a href="#cb43-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-77"><a href="#cb43-77" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb43-78"><a href="#cb43-78" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Train a Simple CNN</span></span>
<span id="cb43-79"><a href="#cb43-79" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb43-80"><a href="#cb43-80" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> models.Sequential([</span>
<span id="cb43-81"><a href="#cb43-81" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>,<span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, input_shape<span class="op">=</span>(<span class="dv">180</span>,<span class="dv">180</span>,<span class="dv">3</span>)),</span>
<span id="cb43-82"><a href="#cb43-82" aria-hidden="true" tabindex="-1"></a>    layers.MaxPooling2D(<span class="dv">2</span>,<span class="dv">2</span>),</span>
<span id="cb43-83"><a href="#cb43-83" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>,<span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>),</span>
<span id="cb43-84"><a href="#cb43-84" aria-hidden="true" tabindex="-1"></a>    layers.MaxPooling2D(<span class="dv">2</span>,<span class="dv">2</span>),</span>
<span id="cb43-85"><a href="#cb43-85" aria-hidden="true" tabindex="-1"></a>    layers.Flatten(),</span>
<span id="cb43-86"><a href="#cb43-86" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>),</span>
<span id="cb43-87"><a href="#cb43-87" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="bu">len</span>(class_names), activation<span class="op">=</span><span class="st">&#39;softmax&#39;</span>)</span>
<span id="cb43-88"><a href="#cb43-88" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb43-89"><a href="#cb43-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-90"><a href="#cb43-90" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">&#39;adam&#39;</span>,</span>
<span id="cb43-91"><a href="#cb43-91" aria-hidden="true" tabindex="-1"></a>              loss<span class="op">=</span><span class="st">&#39;categorical_crossentropy&#39;</span>,</span>
<span id="cb43-92"><a href="#cb43-92" aria-hidden="true" tabindex="-1"></a>              metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</span>
<span id="cb43-93"><a href="#cb43-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-94"><a href="#cb43-94" aria-hidden="true" tabindex="-1"></a><span class="co"># Split data</span></span>
<span id="cb43-95"><a href="#cb43-95" aria-hidden="true" tabindex="-1"></a>split <span class="op">=</span> <span class="bu">int</span>(<span class="fl">0.8</span> <span class="op">*</span> <span class="bu">len</span>(X_filtered))</span>
<span id="cb43-96"><a href="#cb43-96" aria-hidden="true" tabindex="-1"></a>X_train, X_val <span class="op">=</span> X_filtered[:split], X_filtered[split:]</span>
<span id="cb43-97"><a href="#cb43-97" aria-hidden="true" tabindex="-1"></a>y_train, y_val <span class="op">=</span> y[:split], y[split:]</span>
<span id="cb43-98"><a href="#cb43-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-99"><a href="#cb43-99" aria-hidden="true" tabindex="-1"></a><span class="co"># Train</span></span>
<span id="cb43-100"><a href="#cb43-100" aria-hidden="true" tabindex="-1"></a>hist <span class="op">=</span> model.fit(X_train, y_train,</span>
<span id="cb43-101"><a href="#cb43-101" aria-hidden="true" tabindex="-1"></a>                 validation_data<span class="op">=</span>(X_val, y_val),</span>
<span id="cb43-102"><a href="#cb43-102" aria-hidden="true" tabindex="-1"></a>                 epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb43-103"><a href="#cb43-103" aria-hidden="true" tabindex="-1"></a>                 batch_size<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb43-104"><a href="#cb43-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-105"><a href="#cb43-105" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb43-106"><a href="#cb43-106" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Evaluate Model</span></span>
<span id="cb43-107"><a href="#cb43-107" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb43-108"><a href="#cb43-108" aria-hidden="true" tabindex="-1"></a>val_loss, val_acc <span class="op">=</span> model.evaluate(X_val, y_val)</span>
<span id="cb43-109"><a href="#cb43-109" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Validation Accuracy:&quot;</span>, val_acc)</span>
<span id="cb43-110"><a href="#cb43-110" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Validation Loss:&quot;</span>, val_loss)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 1/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 4s 182ms/step - accuracy: 0.2664 - loss: 4.5766 - val_accuracy: 0.0000e+00 - val_loss: 2.9124
Epoch 2/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step - accuracy: 0.3149 - loss: 1.2866 - val_accuracy: 0.0000e+00 - val_loss: 5.3922
Epoch 3/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.6295 - loss: 0.8946 - val_accuracy: 0.0000e+00 - val_loss: 21.2284
Epoch 4/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - accuracy: 0.6345 - loss: 0.9208 - val_accuracy: 0.0000e+00 - val_loss: 13.4660
Epoch 5/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - accuracy: 0.8699 - loss: 0.4787 - val_accuracy: 0.0000e+00 - val_loss: 27.0414
Epoch 6/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - accuracy: 0.8888 - loss: 0.3508 - val_accuracy: 0.0000e+00 - val_loss: 31.3291
Epoch 7/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - accuracy: 0.9697 - loss: 0.1465 - val_accuracy: 0.0000e+00 - val_loss: 32.0950
Epoch 8/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step - accuracy: 0.9879 - loss: 0.0595 - val_accuracy: 0.0000e+00 - val_loss: 47.1160
Epoch 9/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - accuracy: 1.0000 - loss: 0.0313 - val_accuracy: 0.0000e+00 - val_loss: 42.4593
Epoch 10/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 0.0000e+00 - val_loss: 50.6682
Epoch 11/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.0000e+00 - val_loss: 48.4496
Epoch 12/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 33ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.0000e+00 - val_loss: 54.4180
Epoch 13/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.0000e+00 - val_loss: 58.8725
Epoch 14/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 27ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.0000e+00 - val_loss: 61.6651
Epoch 15/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 1.0000 - loss: 8.3584e-04 - val_accuracy: 0.0000e+00 - val_loss: 63.6687
Epoch 16/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - accuracy: 1.0000 - loss: 8.4450e-04 - val_accuracy: 0.0000e+00 - val_loss: 64.2402
Epoch 17/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - accuracy: 1.0000 - loss: 5.0956e-04 - val_accuracy: 0.0000e+00 - val_loss: 65.1034
Epoch 18/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step - accuracy: 1.0000 - loss: 5.2973e-04 - val_accuracy: 0.0000e+00 - val_loss: 65.9650
Epoch 19/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - accuracy: 1.0000 - loss: 4.1578e-04 - val_accuracy: 0.0000e+00 - val_loss: 66.9071
Epoch 20/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - accuracy: 1.0000 - loss: 3.7724e-04 - val_accuracy: 0.0000e+00 - val_loss: 67.8635
2/2 ━━━━━━━━━━━━━━━━━━━━ 1s 368ms/step - accuracy: 0.0000e+00 - loss: 67.6456
Validation Accuracy: 0.0
Validation Loss: 67.86347198486328
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="89"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="9od9ZQaSOMwg" data-outputId="c8047483-467e-4067-9744-1ba94b2444b7">
<div class="sourceCode" id="cb45"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.preprocessing.image <span class="im">import</span> ImageDataGenerator</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> layers, models</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Define a Filter Class</span></span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ImageFilters:</span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;A class that applies sequential filters to an image.&quot;&quot;&quot;</span></span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, brightness<span class="op">=</span><span class="fl">1.0</span>, blur<span class="op">=</span><span class="dv">0</span>, flip<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.brightness <span class="op">=</span> brightness  <span class="co"># brightness factor</span></span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.blur <span class="op">=</span> blur              <span class="co"># Gaussian blur kernel size</span></span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.flip <span class="op">=</span> flip              <span class="co"># horizontal flip</span></span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="bu">apply</span>(<span class="va">self</span>, img):</span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 1. Adjust brightness</span></span>
<span id="cb45-22"><a href="#cb45-22" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> cv2.convertScaleAbs(img, alpha<span class="op">=</span><span class="va">self</span>.brightness, beta<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb45-23"><a href="#cb45-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-24"><a href="#cb45-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 2. Apply blur if specified</span></span>
<span id="cb45-25"><a href="#cb45-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.blur <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb45-26"><a href="#cb45-26" aria-hidden="true" tabindex="-1"></a>            img <span class="op">=</span> cv2.GaussianBlur(img, (<span class="va">self</span>.blur, <span class="va">self</span>.blur), <span class="dv">0</span>)</span>
<span id="cb45-27"><a href="#cb45-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-28"><a href="#cb45-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 3. Flip image horizontally</span></span>
<span id="cb45-29"><a href="#cb45-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.flip:</span>
<span id="cb45-30"><a href="#cb45-30" aria-hidden="true" tabindex="-1"></a>            img <span class="op">=</span> cv2.flip(img, <span class="dv">1</span>)</span>
<span id="cb45-31"><a href="#cb45-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-32"><a href="#cb45-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> img</span>
<span id="cb45-33"><a href="#cb45-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-34"><a href="#cb45-34" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb45-35"><a href="#cb45-35" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Load Dataset (Flowers)</span></span>
<span id="cb45-36"><a href="#cb45-36" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb45-37"><a href="#cb45-37" aria-hidden="true" tabindex="-1"></a>data_dir <span class="op">=</span> Path(<span class="st">&#39;/root/.keras/datasets/flower_photos/flower_photos&#39;</span>)</span>
<span id="cb45-38"><a href="#cb45-38" aria-hidden="true" tabindex="-1"></a>class_names <span class="op">=</span> [p.name <span class="cf">for</span> p <span class="kw">in</span> data_dir.iterdir() <span class="cf">if</span> p.is_dir()]</span>
<span id="cb45-39"><a href="#cb45-39" aria-hidden="true" tabindex="-1"></a>IMG_SIZE <span class="op">=</span> (<span class="dv">180</span>, <span class="dv">180</span>)</span>
<span id="cb45-40"><a href="#cb45-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-41"><a href="#cb45-41" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_images(folder, limit_per_class<span class="op">=</span><span class="dv">50</span>):</span>
<span id="cb45-42"><a href="#cb45-42" aria-hidden="true" tabindex="-1"></a>    images, labels <span class="op">=</span> [], []</span>
<span id="cb45-43"><a href="#cb45-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx, cls <span class="kw">in</span> <span class="bu">enumerate</span>(class_names):</span>
<span id="cb45-44"><a href="#cb45-44" aria-hidden="true" tabindex="-1"></a>        cls_dir <span class="op">=</span> data_dir<span class="op">/</span>cls</span>
<span id="cb45-45"><a href="#cb45-45" aria-hidden="true" tabindex="-1"></a>        img_paths <span class="op">=</span> <span class="bu">list</span>(cls_dir.glob(<span class="st">&#39;*.jpg&#39;</span>))[:limit_per_class]</span>
<span id="cb45-46"><a href="#cb45-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> img_path <span class="kw">in</span> img_paths:</span>
<span id="cb45-47"><a href="#cb45-47" aria-hidden="true" tabindex="-1"></a>            img <span class="op">=</span> cv2.imread(<span class="bu">str</span>(img_path))</span>
<span id="cb45-48"><a href="#cb45-48" aria-hidden="true" tabindex="-1"></a>            img <span class="op">=</span> cv2.resize(img, IMG_SIZE)</span>
<span id="cb45-49"><a href="#cb45-49" aria-hidden="true" tabindex="-1"></a>            images.append(img)</span>
<span id="cb45-50"><a href="#cb45-50" aria-hidden="true" tabindex="-1"></a>            labels.append(idx)</span>
<span id="cb45-51"><a href="#cb45-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(images), np.array(labels)</span>
<span id="cb45-52"><a href="#cb45-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-53"><a href="#cb45-53" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> load_images(data_dir)</span>
<span id="cb45-54"><a href="#cb45-54" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> tf.keras.utils.to_categorical(y, num_classes<span class="op">=</span><span class="bu">len</span>(class_names))</span>
<span id="cb45-55"><a href="#cb45-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-56"><a href="#cb45-56" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb45-57"><a href="#cb45-57" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Apply Random Filter Layer</span></span>
<span id="cb45-58"><a href="#cb45-58" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb45-59"><a href="#cb45-59" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> apply_random_filter_layer(X):</span>
<span id="cb45-60"><a href="#cb45-60" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Apply random filter parameters to each image.&quot;&quot;&quot;</span></span>
<span id="cb45-61"><a href="#cb45-61" aria-hidden="true" tabindex="-1"></a>    new_X <span class="op">=</span> []</span>
<span id="cb45-62"><a href="#cb45-62" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> img <span class="kw">in</span> X:</span>
<span id="cb45-63"><a href="#cb45-63" aria-hidden="true" tabindex="-1"></a>        f <span class="op">=</span> ImageFilters(</span>
<span id="cb45-64"><a href="#cb45-64" aria-hidden="true" tabindex="-1"></a>            brightness<span class="op">=</span>random.uniform(<span class="fl">0.8</span>, <span class="fl">1.2</span>),  <span class="co"># brightness range</span></span>
<span id="cb45-65"><a href="#cb45-65" aria-hidden="true" tabindex="-1"></a>            blur<span class="op">=</span>random.choice([<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">5</span>]),         <span class="co"># blur kernel choices</span></span>
<span id="cb45-66"><a href="#cb45-66" aria-hidden="true" tabindex="-1"></a>            flip<span class="op">=</span>random.choice([<span class="va">True</span>, <span class="va">False</span>])      <span class="co"># randomly flip</span></span>
<span id="cb45-67"><a href="#cb45-67" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb45-68"><a href="#cb45-68" aria-hidden="true" tabindex="-1"></a>        new_X.append(f.<span class="bu">apply</span>(img))</span>
<span id="cb45-69"><a href="#cb45-69" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(new_X)</span>
<span id="cb45-70"><a href="#cb45-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-71"><a href="#cb45-71" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply filter</span></span>
<span id="cb45-72"><a href="#cb45-72" aria-hidden="true" tabindex="-1"></a>X_filtered <span class="op">=</span> apply_random_filter_layer(X)</span>
<span id="cb45-73"><a href="#cb45-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-74"><a href="#cb45-74" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalize images</span></span>
<span id="cb45-75"><a href="#cb45-75" aria-hidden="true" tabindex="-1"></a>X_filtered <span class="op">=</span> X_filtered <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb45-76"><a href="#cb45-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-77"><a href="#cb45-77" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb45-78"><a href="#cb45-78" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Split into Training and Validation Sets</span></span>
<span id="cb45-79"><a href="#cb45-79" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb45-80"><a href="#cb45-80" aria-hidden="true" tabindex="-1"></a>split <span class="op">=</span> <span class="bu">int</span>(<span class="fl">0.8</span> <span class="op">*</span> <span class="bu">len</span>(X_filtered))</span>
<span id="cb45-81"><a href="#cb45-81" aria-hidden="true" tabindex="-1"></a>X_train, X_val <span class="op">=</span> X_filtered[:split], X_filtered[split:]</span>
<span id="cb45-82"><a href="#cb45-82" aria-hidden="true" tabindex="-1"></a>y_train, y_val <span class="op">=</span> y[:split], y[split:]</span>
<span id="cb45-83"><a href="#cb45-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-84"><a href="#cb45-84" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb45-85"><a href="#cb45-85" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Train a Simple CNN</span></span>
<span id="cb45-86"><a href="#cb45-86" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb45-87"><a href="#cb45-87" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> models.Sequential([</span>
<span id="cb45-88"><a href="#cb45-88" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>,<span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, input_shape<span class="op">=</span>(<span class="dv">180</span>,<span class="dv">180</span>,<span class="dv">3</span>)),</span>
<span id="cb45-89"><a href="#cb45-89" aria-hidden="true" tabindex="-1"></a>    layers.MaxPooling2D(<span class="dv">2</span>,<span class="dv">2</span>),</span>
<span id="cb45-90"><a href="#cb45-90" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>,<span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>),</span>
<span id="cb45-91"><a href="#cb45-91" aria-hidden="true" tabindex="-1"></a>    layers.MaxPooling2D(<span class="dv">2</span>,<span class="dv">2</span>),</span>
<span id="cb45-92"><a href="#cb45-92" aria-hidden="true" tabindex="-1"></a>    layers.Flatten(),</span>
<span id="cb45-93"><a href="#cb45-93" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>),</span>
<span id="cb45-94"><a href="#cb45-94" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="bu">len</span>(class_names), activation<span class="op">=</span><span class="st">&#39;softmax&#39;</span>)</span>
<span id="cb45-95"><a href="#cb45-95" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb45-96"><a href="#cb45-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-97"><a href="#cb45-97" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">&#39;adam&#39;</span>,</span>
<span id="cb45-98"><a href="#cb45-98" aria-hidden="true" tabindex="-1"></a>              loss<span class="op">=</span><span class="st">&#39;categorical_crossentropy&#39;</span>,</span>
<span id="cb45-99"><a href="#cb45-99" aria-hidden="true" tabindex="-1"></a>              metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</span>
<span id="cb45-100"><a href="#cb45-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-101"><a href="#cb45-101" aria-hidden="true" tabindex="-1"></a><span class="co"># Train with validation data</span></span>
<span id="cb45-102"><a href="#cb45-102" aria-hidden="true" tabindex="-1"></a>hist <span class="op">=</span> model.fit(</span>
<span id="cb45-103"><a href="#cb45-103" aria-hidden="true" tabindex="-1"></a>    X_train, y_train,</span>
<span id="cb45-104"><a href="#cb45-104" aria-hidden="true" tabindex="-1"></a>    validation_data<span class="op">=</span>(X_val, y_val),  <span class="co"># ✅ validation during training</span></span>
<span id="cb45-105"><a href="#cb45-105" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb45-106"><a href="#cb45-106" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">16</span></span>
<span id="cb45-107"><a href="#cb45-107" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb45-108"><a href="#cb45-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-109"><a href="#cb45-109" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb45-110"><a href="#cb45-110" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. Evaluate Model on Validation Set</span></span>
<span id="cb45-111"><a href="#cb45-111" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb45-112"><a href="#cb45-112" aria-hidden="true" tabindex="-1"></a>val_loss, val_acc <span class="op">=</span> model.evaluate(X_val, y_val)  <span class="co"># ✅ final validation evaluation</span></span>
<span id="cb45-113"><a href="#cb45-113" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Validation Accuracy:&quot;</span>, val_acc)</span>
<span id="cb45-114"><a href="#cb45-114" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Validation Loss:&quot;</span>, val_loss)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 1/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 6s 179ms/step - accuracy: 0.3271 - loss: 5.5896 - val_accuracy: 0.0000e+00 - val_loss: 2.0013
Epoch 2/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step - accuracy: 0.4363 - loss: 1.2784 - val_accuracy: 0.0000e+00 - val_loss: 8.6457
Epoch 3/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - accuracy: 0.6006 - loss: 0.9171 - val_accuracy: 0.0000e+00 - val_loss: 7.7815
Epoch 4/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.7612 - loss: 0.6708 - val_accuracy: 0.0000e+00 - val_loss: 18.0806
Epoch 5/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.8417 - loss: 0.3844 - val_accuracy: 0.0000e+00 - val_loss: 21.3466
Epoch 6/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - accuracy: 0.9263 - loss: 0.2019 - val_accuracy: 0.0000e+00 - val_loss: 28.1298
Epoch 7/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9923 - loss: 0.1056 - val_accuracy: 0.0000e+00 - val_loss: 36.3412
Epoch 8/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - accuracy: 0.9750 - loss: 0.0831 - val_accuracy: 0.0000e+00 - val_loss: 29.0984
Epoch 9/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9871 - loss: 0.0722 - val_accuracy: 0.0000e+00 - val_loss: 24.6746
Epoch 10/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - accuracy: 0.9815 - loss: 0.0976 - val_accuracy: 0.0000e+00 - val_loss: 26.7964
Epoch 11/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - accuracy: 1.0000 - loss: 0.0276 - val_accuracy: 0.0000e+00 - val_loss: 32.6214
Epoch 12/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.0000e+00 - val_loss: 39.3836
Epoch 13/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.0000e+00 - val_loss: 42.0756
Epoch 14/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.0000e+00 - val_loss: 43.3701
Epoch 15/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.0000e+00 - val_loss: 45.4088
Epoch 16/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step - accuracy: 1.0000 - loss: 7.4224e-04 - val_accuracy: 0.0000e+00 - val_loss: 46.7010
Epoch 17/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.0000e+00 - val_loss: 47.2675
Epoch 18/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step - accuracy: 1.0000 - loss: 5.5194e-04 - val_accuracy: 0.0000e+00 - val_loss: 47.8650
Epoch 19/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 29ms/step - accuracy: 1.0000 - loss: 5.7144e-04 - val_accuracy: 0.0000e+00 - val_loss: 48.6355
Epoch 20/20
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 1.0000 - loss: 3.9988e-04 - val_accuracy: 0.0000e+00 - val_loss: 49.2018
2/2 ━━━━━━━━━━━━━━━━━━━━ 1s 370ms/step - accuracy: 0.0000e+00 - loss: 48.6030
Validation Accuracy: 0.0
Validation Loss: 49.201778411865234
</code></pre>
</div>
</div>
</body>
</html>
